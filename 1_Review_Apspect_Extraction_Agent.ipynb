{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34354394-5ebf-438f-a921-9dcb85e6985e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Agent bricks: Review Apspect Extraction Agent\n",
    "\n",
    "This notebook walks through instructions to build an Information Extraction Agent in Agent Bricks to extract aspect insights & sentiments from raw reviews\n",
    "\n",
    "Data Flow: \n",
    "**raw reviews -> review aspect extractions**  -> location aspect daily -> flag all issues -> issue diagnosis and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6b6baa0-eead-485e-af49-5651aee93549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Build Information Extraction Agent\n",
    "\n",
    "Extract Structured Insights from Raw Reviews\n",
    "\n",
    "Example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "021ab836-4825-47b9-a51a-cb619643daed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Information Extraction Agent: Schema Config [`ie_agent_config.json`](resource_configs/ie_agent_config.json)\n",
    "- Instructions: \n",
    "\n",
    "```\n",
    "1. Extract ALL relevant metadata mentioned or implied in the review.\n",
    "   - Include fields such as: star rating, review date, length of stay, and overall sentiment.\n",
    "   - If metadata is missing, set to null — do not guess or invent.\n",
    "\n",
    "2. Extract EVERY relevant aspect from the review text.\n",
    "   - Use the predefined aspect list (Arrival & Departure, Staff & Service, In-Room Experience, Food & Beverage, Facilities & Amenities, Environment & Location, Value & Loyalty).\n",
    "   - For each aspect:\n",
    "       • Identify sentiment (very_positive, positive, neutral, negative, very_negative).\n",
    "       • Include short, verbatim evidence (phrases directly from the review).\n",
    "       • opinion_terms: array of short polarity-bearing words/phrases tied to this aspect (e.g., “spotless,” “friendly,” “overpriced,” “noisy AC”); use verbatim spans when possible\n",
    "   - Deduplicate aspects — each aspect should appear at most once.\n",
    "   - Do not miss subtle mentions, mixed opinions, or multiple details for the same aspect.\n",
    "   - Capture both positive and negative details accurately, without omitting context.\n",
    "\n",
    "3. Extract all **entities** explicitly or implicitly mentioned in the review.\n",
    "   - Entities include: staff roles or names, attractions, nearby locations etc.\n",
    "   - Keep entity names consistent and distinct.\n",
    "   - Do not fabricate entities; if unclear, set to null.\n",
    "   - Avoid redundancy: each unique entity should appear only once.\n",
    "\n",
    "4. Output clean, valid JSON following the specified schema (no extra text, no commentary).\n",
    "   - Ensure consistency across reviews.\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15d53a44-8944-4903-b4cb-8da3191b67f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Batch Inference With IE Agent Endpoint and `AI_QUERY`\n",
    "#### [IE Query in SQL Editor](queries/AI Query Extraction with KIE.dbquery.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "476c533e-4dad-496c-a6df-8cb6c9486a07",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Batch Inference"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE lakehouse_inn_catalog.voc.review_extractions AS\n",
    "WITH query_results AS (\n",
    "  SELECT\n",
    "    review_id,\n",
    "    review_text,\n",
    "    ai_query(\n",
    "      'kie-b59e4876-endpoint',\n",
    "      review_text,\n",
    "      failOnError => false\n",
    "    ) AS respon\n",
    "    \n",
    "    se\n",
    "  FROM (\n",
    "    SELECT review_id, review_text\n",
    "    FROM lakehouse_inn_catalog.voc.raw_reviews\n",
    "  )\n",
    ")\n",
    "SELECT\n",
    "  review_id,\n",
    "  review_text,\n",
    "  response.result AS response,\n",
    "  response.errorMessage AS error\n",
    "FROM query_results;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8087660966816314,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1_Review_Apspect_Extraction_Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
